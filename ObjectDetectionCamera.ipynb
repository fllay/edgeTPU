{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import Image as DisplayImage\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "import imutils\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import sleep\n",
    "import multiprocessing as mp\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "import time\n",
    "import IPython\n",
    "import io\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_fname = \"/home/pi/python/ssd_inception_v2_coco_trt.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showarray(a, fmt='jpeg'):\n",
    "    f = io.BytesIO()\n",
    "    #Image.fromarray(a).save(f, fmt)\n",
    "    a.save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-d7490c9b8970>:3: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "def get_frozen_graph(graph_file):\n",
    "    \"\"\"Read Frozen Graph file from disk.\"\"\"\n",
    "    with tf.gfile.FastGFile(graph_file, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    return graph_def\n",
    "\n",
    "\n",
    "trt_graph = get_frozen_graph(pb_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = ['image_tensor']\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "\n",
    "tf_sess = tf.Session(config=tf_config)\n",
    "\n",
    "tf.import_graph_def(trt_graph, name='')\n",
    "\n",
    "tf_input = tf_sess.graph.get_tensor_by_name(input_names[0] + ':0')\n",
    "tf_scores = tf_sess.graph.get_tensor_by_name('detection_scores:0')\n",
    "tf_boxes = tf_sess.graph.get_tensor_by_name('detection_boxes:0')\n",
    "tf_classes = tf_sess.graph.get_tensor_by_name('detection_classes:0')\n",
    "tf_num_detections = tf_sess.graph.get_tensor_by_name('num_detections:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camThread():\n",
    "\n",
    "    camera_width = 320\n",
    "    camera_height = 240\n",
    "    vidfps = 30\n",
    "\n",
    "    #cam = cv2.VideoCapture(0)\n",
    "    cam = cv2.VideoCapture(\"nvarguscamerasrc ! video/x-raw(memory:NVMM), width=(int)640, height=(int)480,format=(string)NV12, framerate=(fraction)30/1 ! nvvidconv ! video/x-raw, format=(string)BGRx ! videoconvert ! video/x-raw, format=(string)BGR ! appsink\")\n",
    "\n",
    "    #cam.set(cv2.CAP_PROP_FPS, vidfps)\n",
    "    #cam.set(cv2.CAP_PROP_FRAME_WIDTH, camera_width)\n",
    "    #cam.set(cv2.CAP_PROP_FRAME_HEIGHT, camera_height)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "    while True:\n",
    "        try:\n",
    "            t1 = time.perf_counter()\n",
    "\n",
    "            ret, color_image = cam.read()\n",
    "            if not ret:\n",
    "                #print(\"no image\")\n",
    "                continue\n",
    "            frames = color_image\n",
    "\n",
    "            prepimg = color_image[:, :, ::-1].copy()\n",
    "            prepimg = Image.fromarray(prepimg)\n",
    "            draw = ImageDraw.Draw(prepimg)\n",
    "            tinf = time.perf_counter()\n",
    "            image_resized = np.array(prepimg.resize((300, 300)))\n",
    "            #image_resized = np.array(image.resize((300, 300)))\n",
    "            #image_resized = np.array(image.resize((300, 300)))\n",
    "            image = np.array(prepimg)\n",
    "            #print(\"Hello detect !!!!\")\n",
    "            t1 = time.time()\n",
    "            #cores, boxes, classes, num_detections = tf_sess.run([tf_scores, tf_boxes, tf_classes, tf_num_detections], feed_dict={tf_input: image_resized[None, ...]})\n",
    "            scores, boxes, classes, num_detections = tf_sess.run([tf_scores, tf_boxes, tf_classes, tf_num_detections], feed_dict={tf_input: image_resized[None, ...]})\n",
    "            boxes = boxes[0] # index by 0 to remove batch dimension\n",
    "            scores = scores[0]\n",
    "            classes = classes[0]\n",
    "            num_detections = num_detections[0]\n",
    "            #print(num_detections)\n",
    "            for i in range(num_detections.astype(int)):\n",
    "                # scale box to image coordinates\n",
    "                #print(boxes[i])\n",
    "                box = boxes[i] * np.array([image.shape[0], image.shape[1], image.shape[0], image.shape[1]])\n",
    "\n",
    "                # display rectangle\n",
    "                #patch = patches.Rectangle((box[1], box[0]), box[3] - box[1], box[2] - box[0], color='g', alpha=0.3)\n",
    "                #ax.add_patch(patch)\n",
    "\n",
    "                draw.rectangle([box[1], box[0], box[3], box[2]], outline='red')\n",
    "                s='%d (%0.2f) ' % (classes[i], scores[i])\n",
    "\n",
    "                draw.text((box[1], box[2]-20), s , fill='green',font=font)\n",
    "\n",
    "            t2 = time.time()\n",
    "            fps = 1/(t2-t1)\n",
    "            fps_str = 'FPS = %.2f' % fps\n",
    "            draw.text((10,220), fps_str , fill='green', font=font)\n",
    "            showarray(prepimg)\n",
    "            clear_output(wait=True)\n",
    "            res = None\n",
    "        except KeyboardInterrupt:\n",
    "            cam.release() \n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camThread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferencer(results, frameBuffer):\n",
    "\n",
    "    #engine = DetectionEngine(model)\n",
    "    print(\"Hello!!!!\")\n",
    "        \n",
    "    while True:\n",
    "\n",
    "        if frameBuffer.empty():\n",
    "            #print(\"Buffer gone\")\n",
    "            continue\n",
    "       \n",
    "        # Run inference.\n",
    "        color_image = frameBuffer.get()\n",
    "        prepimg = color_image[:, :, ::-1].copy()\n",
    "        prepimg = Image.fromarray(prepimg)\n",
    "        draw = ImageDraw.Draw(prepimg)\n",
    "        tinf = time.perf_counter()\n",
    "        image_resized = np.array(prepimg.resize((300, 300)))\n",
    "        #image_resized = np.array(image.resize((300, 300)))\n",
    "        #image_resized = np.array(image.resize((300, 300)))\n",
    "        image = np.array(prepimg)\n",
    "        #print(\"Hello detect !!!!\")\n",
    "        t1 = time.time()\n",
    "        #cores, boxes, classes, num_detections = tf_sess.run([tf_scores, tf_boxes, tf_classes, tf_num_detections], feed_dict={tf_input: image_resized[None, ...]})\n",
    "        scores, boxes, classes, num_detections = tf_sess.run([tf_scores, tf_boxes, tf_classes, tf_num_detections], feed_dict={tf_input: image_resized[None, ...]})\n",
    "        print(num_detections)\n",
    "\n",
    "            \n",
    "            \n",
    "        t2 = time.time()\n",
    "        fps = 1/(t2-t1)\n",
    "        fps_str = 'FPS = %.2f' % fps\n",
    "        draw.text((10,220), fps_str , fill='green')\n",
    "        showarray(prepimg)\n",
    "        clear_output(wait=True)\n",
    "        #print(\"Hello detect !!!!\")\n",
    "        #print(time.perf_counter() - tinf, \"sec\")\n",
    "        #results.put(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    frameBuffer = mp.Queue(10)\n",
    "    results = mp.Queue()\n",
    "\n",
    "    # Start streaming\n",
    "    p = mp.Process(target=camThread, args=(results, frameBuffer), daemon=True)\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "\n",
    "\n",
    "    # Activation of inferencer\n",
    "    p = mp.Process(target=inferencer, args=(results, frameBuffer), daemon=True)\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "\n",
    "    while True:\n",
    "        sleep(1)\n",
    "\n",
    "finally:\n",
    "    for p in range(len(processes)):\n",
    "        processes[p].terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
